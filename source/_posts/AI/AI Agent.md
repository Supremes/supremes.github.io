---
title: AI Agent 技术核心概念学习路线
tags:
  - AI-Agent
  - LLM
  - RAG
  - Function-Calling
  - ReAct
  - Embedding
  - 向量数据库
categories:
  - AI
description: 深入解析AI Agent的核心技术概念，从Embedding、向量数据库到RAG、Function Calling和ReAct模式，构建完整的LLM应用技术学习路线
abbrlink: 51504
date: 2025-11-28 14:47:28
cover: /imgs/cover/ai_agent.png
---


### **LLM应用技术核心概念学习路线**

这条路线遵循从“基础构件”到“核心能力”再到“高级模式”的逻辑。

------

#### **第一阶段：理解基石——让计算机“懂得”含义（Embedding）**

- **核心问题**：计算机只认识数字，我们如何让它们理解文字、图片、视频的“意思”？
- **什么是 Embedding（嵌入）？** **比喻**：想象一个“语义地图”。每个词（或句子、图片）都是这个地图上的一个点。含义相近的词（如“国王”和“皇帝”）在地图上的位置会非常接近；含义相反的词（如“国王”和“平民”）则相距甚远。 **本质**：Embedding 就是一套算法，将非结构化的数据（文字、图片等）转换成一串有意义的数字向量。这个向量就是数据点在“语义地图”上的**坐标**。 **为什么需要？**只有把数据变成数字坐标，计算机才能进行数学计算，从而比较相似性、进行分类、聚类等操作。**这是后续所有技术的基础。**

#### **第二阶段：实现检索——构建“外部记忆库”（向量数据库）**

- **核心问题**：有了“语义地图”，但当数据量极其庞大时（比如整个公司知识库），如何快速找到与问题最相关的信息？
- **为什么需要向量数据库？** **传统数据库的局限**：它们擅长精确匹配（如“找到id=1的用户”），但不擅长模糊查询（如“找到意思最接近‘可持续发展’的文档”）。 **向量数据库的强项**：它就是为“语义地图”量身定制的数据库。它专门做一件事——**近似最近邻搜索**。你给它一个问题的坐标（问题本身的向量），它能以极快的速度在整个海量向量库中，找到坐标最接近的几个点（即语义最相关的文本片段）。 **本质**：向量数据库是LLM的“外部记忆库”或“知识索引系统”，负责高效、精准地检索信息。

#### **第三阶段：衡量相关性——定义“相似”的标准（Cosine Similarity）**

- **核心问题**：在“语义地图”上，如何数学地定义两个点“相似”？是看它们的直线距离吗？
- **Cosine Similarity（余弦相似度）到底在算个啥？** **比喻**：不比“距离”，比“方向”。想象两个从原点出发的箭头。我们不关心箭头的长短（向量的绝对大小，比如文档的长短），只关心两个箭头指向的方向是否一致。 **计算什么**：它计算的是两个向量之间夹角的余弦值。夹角为0度（方向完全一致），余弦值为1，表示完全相似；夹角为90度（方向垂直），余弦值为0，表示不相关。 **为什么在NLP中常用**：因为它更关注语义上的方向性，而忽略文本长度的影响，这更符合我们判断“意思是否相似”的直觉。

**👉 至此，你已经掌握了RAG的“检索”部分的核心技术栈：`文本 -> Embedding -> 向量数据库 -> 余弦相似度检索`。**

------

#### **第四阶段：构建应用——给LLM“开小灶”（RAG）**

- **核心问题**：LLM内部知识老旧、会产生幻觉（胡说八道），如何让它能回答未知的、专业领域的问题？
- **RAG（检索增强生成）的本质是什么？** **不只是“喂知识库”**：你的理解非常到位。它的本质是**将LLM的推理能力与外部知识源的动态检索能力相结合**。 **工作流程**： **检索**：当用户提出问题时，**不直接**将问题扔给LLM。而是先用上面的技术栈（Embedding+向量数据库+相似度计算），从外部知识库中“精准地检索”出与问题最相关的几段信息（上下文）。 **增强**：将“**原始问题 + 检索到的精准上下文**”一起打包，作为一个新的、信息更丰富的提示词（Prompt）交给LLM。 **生成**：LLM基于这个包含了“标准答案”线索的Prompt来生成回答。 **核心挑战与你的思考一致**：如何“精准地检索”？如果检索到的信息不相关，LLM的回答就会跑偏。因此，检索器的质量（Embedding模型、向量数据库、排序算法）直接决定了RAG的天花板。 **它解决了**：知识更新问题（改知识库即可）、幻觉问题（答案有据可查）、溯源问题（可以注明答案来源）。

------

#### **第五阶段：升级交互——让LLM“学会使用工具”（Function Calling & ReAct）**

- **核心问题**：LLM无法感知实时信息（天气、股价），无法执行具体动作（发邮件、查数据库）。如何让它与外部世界互动？
- **Function Calling（函数调用）的工作流程是怎样的？** **比喻**：给LLM一个“工具清单”，上面列出了每个工具的名称、功能和用法说明（这就是所谓的“函数模式”或“工具模式”）。 **工作流程**： **用户请求**：用户提出一个需要工具的请求，如“今天北京天气怎么样？” **LLM分析**：LLM不会直接回答，而是分析请求，然后**从“工具清单”中选择最合适的工具**（如 `get_weather(location)`）。 **输出调用指令**：LLM**不执行**，而是**返回一个结构化的调用请求**，如 `{"name": "get_weather", "arguments": {"location": "北京"}}`。 **程序执行**：你的外部程序收到这个结构化请求，**代为执行**真正的函数调用（比如调用天气API）。 **返回结果**：将执行结果（如`{"city": "北京", "temperature": "25°C"}`）再交回给LLM。 **LLM组织回答**：LLM将API返回的原始数据组织成自然语言回答用户：“今天北京天气晴朗，气温25摄氏度。” **本质**：一个**决策-执行**的**单次回合**。LLM负责“思考”该用什么工具、传入什么参数，外部系统负责“执行”。
- **ReAct（Reasoning and Acting）模式是怎么让交互更进一步的？** **比喻**：Function Calling 是LLM下达一个命令。而ReAct是LLM在**模拟一个人解决复杂问题的完整思考过程**，这个过程可能包含多个“思考-行动-观察”的循环。 **工作流程**：对于复杂问题（如“我们公司今年销售额最高的产品是什么，它的主要客户画像是什么？”）： **Reason（思考）**：LLM会**先产生一段内部推理**，例如：“要回答这个问题，我需要两步。首先，需要查询数据库找到销售额最高的产品ID。然后，再根据这个产品ID去查询客户画像数据。” **Act（行动）**：根据推理，LLM决定下一步行动，比如调用 `query_database(sql="SELECT ...")`函数。这一步类似Function Calling。 **Observe（观察）**：外部系统执行函数，返回结果（如产品ID是`P-1001`）。这个结果被反馈给LLM。 **循环**：LLM接收到观察结果，**再次进行Reasoning**：“好的，我已经拿到了产品ID是P-1001。接下来，我需要查询客户表...” 然后再次 **Act**，调用另一个函数... **本质**：一个**多步推理的循环框架**。它通过强制LLM展示“思维链”，使其规划能力更强，更能处理需要多步骤工具调用的复杂任务。

### **总结：你的学习路径图**

1. **从Embedding开始**：理解一切是如何从“将信息转化为语义空间坐标”开始的。
2. **学习向量数据库和相似度计算**：理解如何在这个空间里进行高效、精准的检索。这是RAG的基石。
3. **深入理解RAG**：掌握如何通过检索外部知识来增强LLM，解决其核心痛点。
4. **学习Function Calling**：理解LLM与外部工具交互的基本单元。
5. **最终掌握ReAct模式**：理解如何利用LLM的推理能力，串联多个Function Calling来解决复杂问题。

这条路线清晰地展示了现代LLM应用是如何一步步被构建起来的：**从静态的知识检索（RAG），到动态的工具使用（Function Calling），再到复杂的任务分解与规划（ReAct）**。祝你学习顺利！